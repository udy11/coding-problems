{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1onB6kUvo4Z"
   },
   "outputs": [],
   "source": [
    "# import libraries (you may add additional imports but you may not have to)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAQGqqO_vo4d"
   },
   "outputs": [],
   "source": [
    "# get data files\n",
    "#wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
    "\n",
    "#unzip book-crossings.zip\n",
    "\n",
    "books_filename = 'BX-Books.csv'\n",
    "ratings_filename = 'BX-Book-Ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NClILWOiEd6Q"
   },
   "outputs": [],
   "source": [
    "# import csv data into dataframes\n",
    "df_books = pd.read_csv(\n",
    "    books_filename,\n",
    "    encoding = \"ISO-8859-1\",\n",
    "    sep=\";\",\n",
    "    header=0,\n",
    "    names=['isbn', 'title', 'author'],\n",
    "    usecols=['isbn', 'title', 'author'],\n",
    "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
    "\n",
    "df_ratings = pd.read_csv(\n",
    "    ratings_filename,\n",
    "    encoding = \"ISO-8859-1\",\n",
    "    sep=\";\",\n",
    "    header=0,\n",
    "    names=['user', 'isbn', 'rating'],\n",
    "    usecols=['user', 'isbn', 'rating'],\n",
    "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shows how many ratings are given by how many users (left) and received by how many books (right)\n",
    "# original problem asks to remove users if their count is < 200, which removes huge data. also, i think instead high count ones should be removed, specially those outliers\n",
    "# also, original problem asks to remove books if their count is < 100, but this removes a huge amount of data\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].hist(df_ratings.loc[:, 'user'].value_counts(), bins = 50, log = True)\n",
    "axs[0].set_xlabel('number of ratings')\n",
    "axs[0].set_ylabel('number of users')\n",
    "axs[1].hist(df_ratings.loc[:, 'isbn'].value_counts(), bins = 50, log = True)\n",
    "axs[1].set_xlabel('number of ratings')\n",
    "axs[1].set_ylabel('number of books')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this filtering of ratings removes all ratings that are made by a user with < 200 ratings AND book corresponding to that rating has < 100 ratings\n",
    "# groupby creates an object that will do operations based on what it is grouped by. then we take 'user' column to operate on\n",
    "# finally, .transform('count') generates a Series that stores count for each user but in same format as original dataframe, functions can also be passed in transform()\n",
    "df_ratings = df_ratings[(df_ratings.groupby(by = 'isbn')['isbn'].transform('count') >= 100) & (df_ratings.groupby(by = 'user')['user'].transform('count') >= 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates two more columns title and author in df_ratings with matching isbn. any isbn not present in df_books is dropeed from df_ratings\n",
    "df_ratings = df_ratings.merge(right = df_books, on = 'isbn')\n",
    "# the following drops ratings that were given to same title by same user (even though they might have different isbn or author), i think this is not ideal but is expected from problem\n",
    "df_ratings.drop_duplicates(subset = ('title', 'user'), keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a 2d-array where rows are titles, columns are users and values are ratings. any unknown entry is filled with 0.0 (which is questionable)\n",
    "df = df_ratings.pivot(index = 'title', columns = 'user', values = 'rating').fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finds 6 nearest neighbors (including self) treating each row as distances for all users. n_jobs -2 uses all processors (but one) for parallel processing. metric cosine isused because angles between vectors seem to be more appropriate for this problem, than euclidean distances\n",
    "nbrs = NearestNeighbors(n_neighbors = 6, algorithm = 'brute', metric = 'cosine', n_jobs = -2).fit(df)\n",
    "distances, indices = nbrs.kneighbors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "f5ZUd-L1SQz7"
   },
   "outputs": [],
   "source": [
    "# function to return recommended books - this will be tested\n",
    "def get_recommends(book = ''):\n",
    "    if book in df.index:\n",
    "        i0 = df.index.get_loc(book)\n",
    "    else:\n",
    "        return f'book {book} not found'\n",
    "    return [book, [[df.index[indices[i0][i]], distances[i0][i]] for i in range(5, 0, -1)]]    # reverse ordering is illogical but is expected to pass the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jd2SLCh8oxMh"
   },
   "outputs": [],
   "source": [
    "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
    "print(books)\n",
    "\n",
    "def test_book_recommendation():\n",
    "  test_pass = True\n",
    "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
    "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
    "    test_pass = False\n",
    "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
    "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
    "  for i in range(2):\n",
    "    if recommends[1][i][0] not in recommended_books:\n",
    "      test_pass = False\n",
    "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
    "      test_pass = False\n",
    "  if test_pass:\n",
    "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying!\")\n",
    "\n",
    "test_book_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
